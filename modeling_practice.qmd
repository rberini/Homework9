---
title: "Modeling Practice"
author: "Robert Berini"
format: html
editor: visual
execute: 
  warning: false
---

## Load required packages

```{r}
library(tidyverse)
library(tidymodels)
library(baguette)
library(janitor)
library(naniar)
library(skimr)
library(pastecs)
library(vip)
options(scipen = 999, digits = 2)
tidymodels_prefer()
```

## Read data

```{r}
seoul_bike_data <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv",
         locale = locale(encoding = "Latin1"))
```

## Check and manipulate the data

Check for any missing values.

```{r}
vis_miss(seoul_bike_data)
```

Explore columns names, column types, and values.

```{r}
glimpse(seoul_bike_data)
```

Generate basic summary statistics for numeric columns and check the unique values for the categorical variables.

```{r}
skim(seoul_bike_data)
```

Simplify column names.

```{r}
names(seoul_bike_data) <- str_remove(names(seoul_bike_data), "\\s*\\([^\\)]+\\)")
```

Convert the `Date` column into an actual date. Turn the character variables (`Seasons`, `Holiday`, and `Functioning Day`) into factors. Rename the all variables to have easy to use names in snake case.

```{r}
seoul_bike_data <-
  seoul_bike_data |>
  mutate(Date = dmy(Date)) |>
  mutate(across(where(is.character), as.factor)) |>
  clean_names()

seoul_bike_data
```

## Exploratory data analysis

Generate summary statistics across variables.

```{r}
summary(seoul_bike_data)
```

```{r}
skim(seoul_bike_data)
```

Explore `rented_bike_count` by the `functioning_day` variable.

```{r}
seoul_bike_data |>
  group_by(functioning_day) |>
  select(rented_bike_count) |>
  skim()
```

There appear to be no bike rentals on non-functioning days. This implies the business is closed on these days and should be removed from the final data used for analysis.

Create an object that captures all the weather variables.

```{r}
weather_vars <- names(seoul_bike_data[4:9])
weather_vars
```

To simplify analysis, summarize across the hours so that each day has one observation associated with it:

-   `group_by()` the `date`, `seasons`, and `holiday` variables
-   find the `sum` of the `rented_bike_count`, `rainfall`, and `snowfall` variables
-   find the `mean` of all the weather related variables

```{r}
new_seoul_bike_data <-
  seoul_bike_data |>
  filter(functioning_day == "Yes") |>
  group_by(date, seasons, holiday) |>
  summarise(across(c(rented_bike_count, rainfall, snowfall), sum),
            across(all_of(weather_vars), mean))

new_seoul_bike_data
```

Recreate basic summary statistics.

```{r}
summary(new_seoul_bike_data)
```

```{r}
stat.desc(new_seoul_bike_data[,4:ncol(new_seoul_bike_data)], basic = F)
```

Report correlation between numeric variables.

```{r}
cor(new_seoul_bike_data[,4:ncol(new_seoul_bike_data)])
```

Create some plots to explore relationships.

```{r}
new_seoul_bike_data |>
  ggplot(aes(x = temperature, y = rented_bike_count)) +
  geom_point(aes(color = holiday)) +
  facet_wrap(~ seasons) +
  ggtitle("Relationship Between Rented Bike Count and Solar Radiation",
          subtitle = "Considering Effects of Season and Holiday") +
  xlab("Temperature") +
  ylab("Rented Bike Count")
```

```{r}
new_seoul_bike_data |>
  ggplot(aes(x = wind_speed, y = rented_bike_count)) +
  geom_point() +
  facet_wrap(~ seasons) +
  ggtitle("Relationship Between Rented Bike Count and Wind Speed",
          subtitle = "Considering Effects of Season") +
  xlab("Wind Speed") +
  ylab("Rented Bike Count")
```

```{r}
new_seoul_bike_data |>
  ggplot(aes(x = solar_radiation, y = rented_bike_count)) +
  geom_point() +
  facet_wrap(~ seasons) +
  ggtitle("Relationship Between Rented Bike Count and Solar Radiation",
          subtitle = "Considering Effects of Season") +
  xlab("Solar Radiation") +
  ylab("Rented Bike Count")
```

```{r}
new_seoul_bike_data |>
  mutate(snowfall = factor(if_else(snowfall == 0, "No Snow", "Snow"))) |>
  ggplot(aes(x = snowfall, y = rented_bike_count)) +
  geom_boxplot() +
  ggtitle("Distribution of Rented Bike Count for Snowy Versus Non-Snowy Days") +
  xlab("Snowfall") +
  ylab("Rented Bike Count")
```

```{r}
new_seoul_bike_data |>
  mutate(rainfall = factor(if_else(rainfall == 0, "No Rain", "Rain"))) |>
  ggplot(aes(x = rainfall, y = rented_bike_count)) +
  geom_boxplot() +
  ggtitle("Distribution of Rented Bike Count for Rainy Versus Non-Rainy Days") +
  xlab("Rainfall") +
  ylab("Rented Bike Count")
```

```{r}
new_seoul_bike_data |>
  mutate(weekpart = factor(if_else(wday(date, label = T) %in% c("Sun", "Sat"), "Weekend", "Weekday"))) |>
  ggplot(aes(x = weekpart, y = rented_bike_count)) +
  geom_boxplot() +
  ggtitle("Distribution of Rented Bike Count for Weekdays Versus Weekends") +
  xlab("Part of Week") +
  ylab("Rented Bike Count")
```

```{r}
new_seoul_bike_data |>
  ggplot(aes(x = holiday, y = rented_bike_count)) +
  geom_boxplot() +
  ggtitle("Distribution of Rented Bike Count for Holidays Versus Non-Holidays") +
  xlab("Holiday") +
  ylab("Rented Bike Count")
```

## Split the data

Split the data into a training and test set (75/25 split). Use the `strata` argument to stratify the split on the `seasons` variable.

```{r}
set.seed(1017)
bike_split <- initial_split(new_seoul_bike_data, prop = 0.75, strata = "seasons")
bike_train <- training(bike_split)
bike_test <- testing(bike_split)
```

On the training set, create a 10 fold CV split.

```{r}
bike_10_fold <- vfold_cv(bike_train, 10)
```

## Create recipes

For the 1st recipe:

-   ignore the date variable for modeling, but use it to create a weekday/weekend (factor) variable called `weekpart`
-   standardize the numeric variables
-   create dummy variables for the `seasons`, `holiday`, and new `weekpart` variable

```{r}
bike_rec_1 <-
  recipe(rented_bike_count ~ ., data = bike_train) |>
  step_date(date, features = "dow") |>
  step_mutate(weekpart = factor(if_else(date_dow %in% c("Sun", "Sat"), "Weekend", "Weekday"))) |>
  step_rm(date, date_dow) |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(seasons, holiday, weekpart)
```

```{r}
bike_rec_1 |>
  prep(training = bike_train) |>
  bake(bike_train)
```

For the 2nd recipe:

-   do the same steps as above
-   add in interactions between `seasons` and `holiday`, `seasons` and `temperature`, and `temperature` and `rainfall`

```{r}
bike_rec_2 <-
  bike_rec_1 |>
  step_interact(~ starts_with("holiday"):starts_with("seasons") +
                  temperature:starts_with("seasons") +
                  temperature:rainfall)
```

```{r}
bike_rec_2 |>
  prep(training = bike_train) |>
  bake(bike_train)
```

For the 3rd recipe:

-   do the same as the 2nd recipe
-   add in quadratic terms for each numeric predictor

```{r}
bike_rec_3 <-
  recipe(rented_bike_count ~ ., data = bike_train) |>
  step_date(date, features = "dow") |>
  step_mutate(weekpart = factor(if_else(date_dow %in% c("Sun", "Sat"), "Weekend", "Weekday"))) |>
  step_rm(date, date_dow) |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_poly(all_numeric(), -all_outcomes(), degree = 2, keep_original_cols = T) |>
  step_rm(ends_with("poly_1")) |>
  step_dummy(seasons, holiday, weekpart) |>
  step_interact(~ starts_with("holiday"):starts_with("seasons") +
                  temperature:starts_with("seasons") +
                  temperature:rainfall)
```

```{r}
bike_rec_3 |>
  prep(training = bike_train) |>
  bake(bike_train)
```

Define metrics set.

```{r}
metrics_set <- metric_set(rmse, mae)
```


## Fit MLR Models

Set up linear model fit to use the `“lm”` engine.

```{r}
lm_mod <-
  linear_reg() |>
  set_engine("lm")
```

Fit models for recipe 1 using 10 fold CV via `fit_resamples()` and consider the training set CV error.

```{r}
bike_wfl_1 <-
  workflow() |>
  add_recipe(bike_rec_1) |>
  add_model(lm_mod)
```

```{r}
bike_cv_fits_1 <-
  bike_wfl_1 |>
  fit_resamples(bike_10_fold, metrics = metrics_set)
```

```{r}
bike_cv_1_metrics <-
  bike_cv_fits_1 |>
  collect_metrics()
```

Repeat process for recipe 2.

```{r}
bike_wfl_2 <-
  workflow() |>
  add_recipe(bike_rec_2) |>
  add_model(lm_mod)
```

```{r}
bike_cv_fits_2 <-
  bike_wfl_2 |>
  fit_resamples(bike_10_fold, metrics = metrics_set)
```

```{r}
bike_cv_2_metrics <-
  bike_cv_fits_2 |>
  collect_metrics()
```

Repeat process for recipe 3.

```{r}
bike_wfl_3 <-
  workflow() |>
  add_recipe(bike_rec_3) |>
  add_model(lm_mod)
```

```{r}
bike_cv_fits_3 <-
  bike_wfl_3 |>
  fit_resamples(bike_10_fold, metrics = metrics_set)
```

```{r}
bike_cv_3_metrics <-
  bike_cv_fits_3 |>
  collect_metrics()
```

Consider the training set CV error across recipes to choose a best model.

```{r}
rbind(bike_cv_1_metrics, bike_cv_2_metrics, bike_cv_3_metrics) |>
  filter(.metric == "rmse") |>
  mutate(model = c("Recipe 1", "Recipe 2", "Recipe 3")) |>
  select(model, "mean_rmse" = mean, n, std_err)
```

```{r}
bike_best_fit <-
  bike_wfl_3 |>
  fit(bike_train)
```

```{r}
bike_best_fit |>
  tidy()
```

Using the best model, fit the model to the entire training data set using the `last_fit()` function. Compute the RMSE and MAE metrics on the test set.

```{r}
bike_wfl_3 |>
  last_fit(split = bike_split, metrics = metrics_set) |>
  collect_metrics()
```

Obtain the final model (fit on the entire training set) coefficient table using `extract_fit_parsnip()` and `tidy()`.

```{r}
extract_fit_parsnip(
  bike_wfl_3 |>
  last_fit(split = bike_split)
) |>
  tidy() |>
  print(n=Inf)
```

Collect final RMSE and MAE metrics for best MLR model.

```{r}
mlr_metrics <-
  bike_wfl_3 |>
  last_fit(split = bike_split, metrics = metrics_set) |>
  collect_metrics()
mlr_metrics
```

## Fit LASSO Model

Set up LASSO model fit to use the `“glm”` engine.

```{r}
lasso_spec <-
  linear_reg(penalty = tune(), mixture = 1) |>
  set_engine("glmnet")
```

Create workflow using recipe 3.

```{r}
bike_lasso_wfl <-
  workflow() |>
  add_recipe(bike_rec_3) |>
  add_model(lasso_spec)
```

Create a tuning grid to consider varying penalties.

```{r}
set.seed(1017)

bike_lasso_grid <-
  bike_lasso_wfl |>
  tune_grid(resamples = bike_10_fold,
            grid = grid_regular(penalty(range = c(-4, 2)), levels = 500),
            metrics = metrics_set) 
```

Sort models by tuned penalty parameter with lowest RMSE.

```{r}
bike_lasso_grid |>
  collect_metrics() |>
  filter(.metric == "rmse") |>
  arrange(mean)
```

Show model performance at different levels of the penalty parameter.

```{r}
bike_lasso_grid |>
  collect_metrics() |>
  filter(.metric == "rmse") |>
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_line() +
  scale_x_log10() +
  scale_color_viridis_d()
```

Identify penalty parameter with lowest RMSE.

```{r}
lowest_rmse <- 
  bike_lasso_grid |>
  select_best(metric = "rmse")
lowest_rmse
```


```{r}
bike_lasso_final <- 
  bike_lasso_wfl |>
  finalize_workflow(lowest_rmse) |>
  fit(bike_train)

tidy(bike_lasso_final) |>
  print(n=Inf)
```

Using the best model, fit the model to the entire training data set using the `last_fit()` function. Compute the RMSE and MAE metrics on the test set.

```{r}
bike_lasso_wfl |>
  finalize_workflow(lowest_rmse) |>
  last_fit(split = bike_split, metrics = metrics_set) |>
  collect_metrics()
```

Obtain the final model (fit on the entire training set) coefficient table using `extract_fit_parsnip()` and `tidy()`.

```{r}
bike_lasso_wfl |>
  finalize_workflow(lowest_rmse) |>
  last_fit(split = bike_split, metrics = metrics_set) |>
  extract_fit_parsnip() |>
  tidy() |>
  print(n=Inf)
```

Collect final RMSE and MAE metrics for best LASSO model.

```{r}
lasso_metrics <-
  bike_lasso_wfl |>
  finalize_workflow(lowest_rmse) |>
  last_fit(split = bike_split, metrics = metrics_set) |>
  collect_metrics()
lasso_metrics
```

## Fit Regression Tree Model

Set up Regression Tree fit to use the `“rpart”` engine.

```{r}
tree_mod <- decision_tree(tree_depth = tune(),
                          min_n = 10,
                          cost_complexity = tune()) |>
  set_engine("rpart") |>
  set_mode("regression")
```

Create workflow using recipe 1.

```{r}
bike_tree_wfl <- 
  workflow() |>
  add_recipe(bike_rec_1) |>
  add_model(tree_mod)
```

Create a tuning grid to consider varying levels of tree depth and cost complexity.

```{r}
set.seed(1017)

tree_fits <-
  bike_tree_wfl |> 
  tune_grid(resamples = bike_10_fold, grid = 50,
            metrics = metrics_set)
```

Sort models by tuned tree depth and cost complexity parameters with lowest RMSE.

```{r}
tree_fits |>
  collect_metrics() |>
  filter(.metric == "rmse") |>
  arrange(mean)
```

Show model performance at different levels of tree depth and cost complexity parameters.

```{r}
tree_fits |>
  collect_metrics() |>
  filter(.metric == "rmse") |>
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d()
```

Identify parameter combination with lowest RMSE.

```{r}
tree_best_params <-
  tree_fits |>
  select_best(metric = "rmse")
tree_best_params
```

Using the best model, fit the model to the entire training data set using the `last_fit()` function. Compute the RMSE and MAE metrics on the test set.

```{r}
bike_tree_final_fit <-
  bike_tree_wfl |>
  finalize_workflow(tree_best_params) |>
  last_fit(split = bike_split, metrics = metrics_set)

bike_tree_final_fit |>
  collect_metrics()
```

Visualize the regression tree.

```{r}
bike_tree_final_fit |>
  extract_workflow() |>
  extract_fit_engine() |>
  rpart.plot::rpart.plot(roundint = F)
```

Collect final RMSE and MAE metrics for best Regression Tree model.

```{r}
tree_metrics <-
  bike_tree_final_fit |>
  collect_metrics()
tree_metrics
```

## Fit Bagged Tree Model

Set up Bagged Tree fit to use the `“rpart”` engine.

```{r}
bag_mod <- bag_tree(tree_depth = tune(),
                          min_n = 10,
                          cost_complexity = tune()) |>
  set_engine("rpart") |>
  set_mode("regression") |>
  translate()
```

Create workflow using recipe 1.

```{r}
bike_bag_wfl <- 
  workflow() |>
  add_recipe(bike_rec_1) |>
  add_model(bag_mod)
```

Create a tuning grid to consider varying levels of tree depth and cost complexity.

```{r}
set.seed(1017)

bag_fits <-
  bike_bag_wfl |> 
  tune_grid(resamples = bike_10_fold, grid = 50,
            metrics = metrics_set)
```

Sort models by tuned tree depth and cost complexity parameters with lowest RMSE.

```{r}
bag_fits |>
  collect_metrics() |>
  filter(.metric == "rmse") |>
  arrange(mean)
```

Show model performance at different levels of tree depth and cost complexity parameters.

```{r}
bag_fits |>
  collect_metrics() |>
  filter(.metric == "rmse") |>
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d()
```

Identify parameter combination with lowest RMSE.

```{r}
bag_best_params <-
  bag_fits |>
  select_best(metric = "rmse")
bag_best_params
```

Using the best model, fit the model to the entire training data set using the `last_fit()` function. Compute the RMSE and MAE metrics on the test set.

```{r}
bike_bag_final_fit <-
  bike_bag_wfl |>
  finalize_workflow(bag_best_params) |>
  last_fit(split = bike_split, metrics = metrics_set)

bike_bag_final_fit |>
  collect_metrics()
```

Produce a variable importance plot.

```{r}
bike_bag_final_model <- extract_fit_engine(bike_bag_final_fit) 
bike_bag_final_model$imp |>
  mutate(term = factor(term, levels = term)) |>
  ggplot(aes(x = reorder(term, value), y = value)) + 
  geom_bar(stat ="identity") +
  coord_flip() +
  theme(axis.title.y = element_blank()) +
  ylab("Importance")
```

Collect final RMSE and MAE metrics for best Bagged Tree model.

```{r}
bag_metrics <-
  bike_bag_final_fit |>
  collect_metrics()
bag_metrics
```

## Fit Random Forest Model

Set up Random Forest fit to use the `“ranger”` engine.

```{r}
rf_mod <- rand_forest(mtry = tune(),
                      min_n = 10,
                      trees = tune()) |>
  set_engine("ranger", importance = "impurity") |>
  set_mode("regression")
```

Create workflow using recipe 1.

```{r}
bike_rf_wfl <- 
  workflow() |>
  add_recipe(bike_rec_1) |>
  add_model(rf_mod)
```

Create a tuning grid to consider varying levels of number of predictors that will be randomly sampled at each split and number of trees contained in the ensemble.

```{r}
set.seed(1017)

rf_fits <-
  bike_rf_wfl |> 
  tune_grid(resamples = bike_10_fold, grid = 50,
            metrics = metrics_set)
```

Sort models by tuned parameters with lowest RMSE.

```{r}
rf_fits |>
  collect_metrics() |>
  filter(.metric == "rmse") |>
  arrange(mean)
```

Identify parameter combination with lowest RMSE.

```{r}
rf_best_params <-
  rf_fits |>
  select_best(metric = "rmse")
rf_best_params
```

Using the best model, fit the model to the entire training data set using the `last_fit()` function. Compute the RMSE and MAE metrics on the test set.

```{r}
bike_rf_final_fit <-
  bike_rf_wfl |>
  finalize_workflow(rf_best_params) |>
  last_fit(split = bike_split, metrics = metrics_set)

bike_rf_final_fit |>
  collect_metrics()
```

Produce a variable importance plot.

```{r}
bike_rf_final_model <- extract_fit_engine(bike_rf_final_fit) 
bike_rf_final_model |>
  vip(num_features = 20)
```

Collect final RMSE and MAE metrics for best Random Forest model.

```{r}
rf_metrics <-
  bike_rf_final_fit |>
  collect_metrics()
rf_metrics
```

## Select the Best Model

Compare all final models using both RMSE and MAE

```{r}
rbind(mlr_metrics, lasso_metrics, tree_metrics, bag_metrics, rf_metrics) |>
  filter(.metric == "rmse") |>
  mutate(model = c("MLR", "LASSO", "Tree", "Bagged Tree", "Random Forest")) |>
  select(model, "mean_rmse" = .estimate)
```

```{r}
rbind(mlr_metrics, lasso_metrics, tree_metrics, bag_metrics, rf_metrics) |>
  filter(.metric == "mae") |>
  mutate(model = c("MLR", "LASSO", "Tree", "Bagged Tree", "Random Forest")) |>
  select(model, "mean_mae" = .estimate)
```

The best performing model is **Bagged Tree**.

For the overall best model, fit it to the entire data set.

```{r}
set.seed(1017)

final_best_wfl <- 
  bike_bag_wfl |> 
  finalize_workflow(bag_best_params)
```


```{r}
final_metrics <-
  final_best_wfl |> 
  last_fit(split = bike_split, metrics = metrics_set) |>
  collect_metrics()

final_metrics
```
